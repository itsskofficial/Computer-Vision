{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A61B98ruc0hK"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow opencv-python matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import uuid\n",
        "import random\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow import GradientTape\n",
        "from tensorflow.train import Checkpoint\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.utils import Progbar\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.metrics import Precision, Recall\n",
        "from tensorflow.keras.losses import BinaryCrossentropy\n",
        "from tensorflow.keras.layers import Layer, Conv2D, Dense, MaxPooling2D, Input, Flatten"
      ],
      "metadata": {
        "id": "2CD44xRKdOpo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gpus = tf.config.experimental.list_physical_devices(\"GPU\")\n",
        "for gpu in gpus :\n",
        "  tf.config.experimental.set_memory_growth(gpu, True)"
      ],
      "metadata": {
        "id": "n3b665RsgLMD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.compat.v1.enable_eager_execution()"
      ],
      "metadata": {
        "id": "V7kCfv83A6ER"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "POSITIVE_PATH = os.path.join(\"data\", \"positive\")\n",
        "NEGATIVE_PATH = os.path.join(\"data\", \"negative\")\n",
        "ANCHOR_PATH = os.path.join(\"data\", \"anchor\")"
      ],
      "metadata": {
        "id": "QXYHNmt1iywh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs(POSITIVE_PATH)\n",
        "os.makedirs(NEGATIVE_PATH)\n",
        "os.makedirs(ANCHOR_PATH)"
      ],
      "metadata": {
        "id": "u2XNCYjDjlBb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://vis-www.cs.umass.edu/lfw/lfw.tgz"
      ],
      "metadata": {
        "id": "kU0aw0ZqkVzl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!tar -xf lfw.tgz"
      ],
      "metadata": {
        "id": "NnBIz2IKnQli"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for directory in os.listdir(\"lfw\") :\n",
        "  for file in os.listdir(os.path.join(\"lfw\", directory)) :\n",
        "    OLD_PATH = os.path.join(\"lfw\", directory, file)\n",
        "    NEW_PATH = os.path.join(NEGATIVE_PATH, file)\n",
        "    os.replace(OLD_PATH, NEW_PATH)"
      ],
      "metadata": {
        "id": "J31G7uMln5uE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "capture = cv2.VideoCapture(0)\n",
        "\n",
        "while capture.isOpened() :\n",
        "  ret, frame = capture.read()\n",
        "  frame = frame[100 : 350, 200 : 450, : ]\n",
        "\n",
        "  if cv2.waitKey(1) & 0XFF == ord(\"a\") :\n",
        "    img_name = os.path.join(ANCHOR_PATH, f\"{uuid.uuid1()}.jpg\")\n",
        "    cv2.imwrite(img_name, frame)\n",
        "\n",
        "  if cv2.waitKey(1) & 0XFF == ord(\"p\") :\n",
        "    img_name = os.path.join(POSITIVE_PATH, f\"{uuid.uuid1()}.jpg\")\n",
        "    cv2.imwrite(img_name, frame)\n",
        "\n",
        "  cv2.imshow(\"Image Collection\", frame)\n",
        "\n",
        "  if cv2.waitKey(1) & 0XFF == ord(\"q\") :\n",
        "    break\n",
        "\n",
        "capture.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "g4FEK9xZpSzC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(frame[100 : 350, 200 : 450, : ])"
      ],
      "metadata": {
        "id": "7bDC-hQXuywu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "anchor_dir = tf.data.Dataset.list_files(ANCHOR_PATH + \"/*.jpg\").take(300)\n",
        "positive_dir = tf.data.Dataset.list_files(POSITIVE_PATH + \"/*.jpg\").take(300)\n",
        "negative_dir = tf.data.Dataset.list_files(NEGATIVE_PATH + \"/*.jpg\").take(300)"
      ],
      "metadata": {
        "id": "PzN9CD3tz-uX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(file_path) :\n",
        "  byte_img = tf.io.read_file(file_path)\n",
        "  img = tf.io.decode_jpeg(byte_img)\n",
        "  img = tf.image.resize(img, (100, 100))\n",
        "  img = img / 255.0\n",
        "\n",
        "  return img"
      ],
      "metadata": {
        "id": "gfolWqO20pTN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "positives = tf.data.Dataset.zip((anchor_dir, positive_dir, tf.data.Dataset.from_tensor_slices(tf.ones(len(anchor_dir)))))\n",
        "negatives = tf.data.Dataset.zip((anchor_dir, negative_dir, tf.data.Dataset.from_tensor_slices(tf.zeros(len(anchor_dir)))))\n",
        "data = positives.concatenate(negatives)"
      ],
      "metadata": {
        "id": "F4czgrz83aYR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_util(input_img, validation_img, label) :\n",
        "  return (preprocess(input_img), preprocess(validation_img), label)"
      ],
      "metadata": {
        "id": "MqACVBu85HSk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = data.map(preprocess_util)\n",
        "data = data.cache()\n",
        "data = data.shuffle(buffer_size = 1024)"
      ],
      "metadata": {
        "id": "ikjj9NeK5tmK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = data.take(round(len(data) * 0.7))\n",
        "train_data = train_data.batch(16)\n",
        "train_data = train_data.prefetch(8)"
      ],
      "metadata": {
        "id": "UDo1bisW7pfe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " test_data = data.skip(round(len(data) * 0.7))\n",
        " test_data = test_data.take(round(len(data) * 0.3))\n",
        " test_data = test_data.batch(16)\n",
        " test_data = test_data.prefetch(8)"
      ],
      "metadata": {
        "id": "3uXg-YE68CDX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_embeddings_model() :\n",
        "  input_layer = Input(shape = (100, 100, 3), name = \"input_layer\")\n",
        "  convolution_layer_1 = Conv2D(64, (10, 10), activation = \"relu\", name = \"convolution_layer_1\")(input_layer)\n",
        "  max_pooling_layer_1 = MaxPooling2D(64, (2, 2), padding = \"same\", name = \"max_pooling_layer_1\")(convolution_layer_1)\n",
        "  convolution_layer_2 = Conv2D(128, (8, 8), activation = \"relu\", name = \"convolution_layer_2\")(max_pooling_layer_1)\n",
        "  max_pooling_layer_2 = MaxPooling2D(64, (2, 2), padding = \"same\", name = \"max_pooling_layer_2\")(convolution_layer_2)\n",
        "  convolution_layer_3 = Conv2D(128, (6, 6), activation = \"relu\", name = \"convolution_layer_3\")(max_pooling_layer_2)\n",
        "  max_pooling_layer_3 = MaxPooling2D(64, (2, 2), padding = \"same\", name = \"max_pooling_layer_3\")(convolution_layer_3)\n",
        "  convolution_layer_4 = Conv2D(256, (4, 4), activation = \"relu\", name = \"convolution_layer_4\")(max_pooling_layer_3)\n",
        "  flatten_layer_1 = Flatten()(convolution_layer_4)\n",
        "  dense_layer_1 = Dense(4096, activation = \"sigmoid\")(flatten_layer_1)\n",
        "\n",
        "  return Model(inputs = [input_layer], outputs = [dense_layer_1], name = \"embedding_model\")"
      ],
      "metadata": {
        "id": "05agbkld83QN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_model = create_embeddings_model()"
      ],
      "metadata": {
        "id": "TYG8nYxK0q9z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_model.summary()"
      ],
      "metadata": {
        "id": "q6Etf-ja0ysN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class L1Dist(Layer) :\n",
        "  def __init__(self, **kwargs) :\n",
        "    super().__init__()\n",
        "\n",
        "  def call(self, input_embedding, validation_embedding) :\n",
        "    return tf.math.abs(input_embedding -  validation_embedding)"
      ],
      "metadata": {
        "id": "5_ALDir31DiB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_siamese_model() :\n",
        "  input_image = Input(name = \"input_img\", shape = (100, 100, 3))\n",
        "  validation_image = Input(name = \"validation_img\", shape = (100, 100, 3))\n",
        "  siamese_layer = L1Dist()\n",
        "  siamese_layer._name = \"l1_distance_layer\"\n",
        "  distances = siamese_layer(embedding_model(input_image), embedding_model(validation_image))\n",
        "  classification_layer = Dense(1, activation = \"sigmoid\")(distances)\n",
        "\n",
        "  return Model(inputs = [input_image, validation_image], outputs = [classification_layer], name = \"siamese_model\")"
      ],
      "metadata": {
        "id": "p8xcYjHP2U8p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "siamese_model = create_siamese_model()"
      ],
      "metadata": {
        "id": "qqEj37We4sDq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "siamese_model.summary()"
      ],
      "metadata": {
        "id": "gnYT3_Es9YCZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss = BinaryCrossentropy()\n",
        "optimizer = Adam(learning_rate = 0.003)"
      ],
      "metadata": {
        "id": "ZTR7oUZE5jmw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_dir = \"training_checkpoints\"\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = Checkpoint(opt = optimizer, model = siamese_model)"
      ],
      "metadata": {
        "id": "6DDxOSPU6lp_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def train_step(batch) :\n",
        "  with GradientTape() as tape :\n",
        "    X = batch[:2]\n",
        "    y = batch[2]\n",
        "    y_hat = siamese_model(X, training = True)\n",
        "    step_loss = loss(y, y_hat)\n",
        "\n",
        "  grad = tape.gradient(step_loss, siamese_model.trainable_variables)\n",
        "  optimizer.apply_gradients(zip(grad, siamese_model.trainable_variables))\n",
        "\n",
        "  return step_loss"
      ],
      "metadata": {
        "id": "7Mb9ULCK7aZt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(data, epochs):\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        print('\\nEpoch {}/{}'.format(epoch, epochs))\n",
        "        progress_bar = Progbar(len(data))\n",
        "\n",
        "        r = Recall()\n",
        "        p = Precision()\n",
        "\n",
        "        for idx, batch in enumerate(data):\n",
        "            step_loss = train_step(batch)\n",
        "            y_hat = siamese_model.predict(batch[:2])\n",
        "            r.update_state(batch[2], y_hat)\n",
        "            p.update_state(batch[2], y_hat)\n",
        "            progress_bar.update(idx+1)\n",
        "        print(f\"Loss : {step_loss.numpy()} Recall : {r.result().numpy()} Precision : {p.result().numpy()}\")\n",
        "\n",
        "        if epoch % 10 == 0:\n",
        "            checkpoint.save(file_prefix=checkpoint_prefix)"
      ],
      "metadata": {
        "id": "CTO-mJiU-rgs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(train_data, 50)"
      ],
      "metadata": {
        "id": "qy4V5kt1DMkI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_input, test_validation, y = test_data.as_numpy_iterator().next()"
      ],
      "metadata": {
        "id": "mdzYtgtg__3t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_hat = siamese_model.predict([test_input, test_validation])"
      ],
      "metadata": {
        "id": "B4leb_RFD0gA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_hat = [1 if prediction > 0.5 else 0 for prediction in y_hat]"
      ],
      "metadata": {
        "id": "3_QmfOkoEJLQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_hat"
      ],
      "metadata": {
        "id": "YYH0Y_3U6exD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "precision, recall = Precision(), Recall()\n",
        "precision.update_state(y, y_hat)\n",
        "recall.update_state(y, y_hat)\n",
        "precision.result().numpy(), recall.result().numpy()"
      ],
      "metadata": {
        "id": "xS1e4xvXFE92"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize = (18, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.imshow(test_input[0])\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.imshow(test_validation[0])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "OEakDSBo7Gdp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "siamese_model.save(\"model\")"
      ],
      "metadata": {
        "id": "KZDhkhuM9aHK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.load_model(\"model\", custom_objects = {\"L1Dist\" : L1Dist, \"BinaryCrossentropy\" : BinaryCrossentropy})"
      ],
      "metadata": {
        "id": "JN0YzZQk-9h7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.predict([test_input, test_validation])"
      ],
      "metadata": {
        "id": "73huRKE4_1Fr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "jekd6HeL_7cl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r model.zip \"model\""
      ],
      "metadata": {
        "id": "tpRh-yyFCfM6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.mkdir(\"application_data\")\n",
        "os.mkdir(\"application_data/validation_images\")\n",
        "os.mkdir(\"application_data/input_image\")"
      ],
      "metadata": {
        "id": "BqTsPrLIFkr_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "INPUT_PATH = os.path.join(\"application_data\", \"input_image\")\n",
        "VALIDATION_PATH = os.path.join(\"application_data\", \"validation_images\")"
      ],
      "metadata": {
        "id": "V9D-bG0MEn9U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "capture = cv2.VideoCapture(3)\n",
        "\n",
        "while capture.isOpened() :\n",
        "  ret, frame = capture.read()\n",
        "  frame = frame[100 : 350, 200 : 450, : ]\n",
        "\n",
        "  if cv2.waitKey(1) & 0XFF == ord(\"v\") :\n",
        "    img_name = os.path.join(VALIDATION_PATH, f\"{uuid.uuid1()}.jpg\")\n",
        "    cv2.imwrite(img_name, frame)\n",
        "\n",
        "  cv2.imshow(\"Verification Images\", frame)\n",
        "\n",
        "  if cv2.waitKey(1) & 0XFF == ord(\"q\") :\n",
        "    break\n",
        "\n",
        "capture.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "P2saxSABEhQ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def verify(model, detection_threshold, verification_threshold) :\n",
        "  results = []\n",
        "  for image in os.listdir(VALIDATION_PATH) :\n",
        "    input_img = preprocess(os.path.join(INPUT_PATH, \"img.jpg\"))\n",
        "    validation_img = preprocess(os.path.join(VALIDATION_PATH, image))\n",
        "    result = model.predict(list(np.expand_dims([input_img, validation_img], axis = 1)))\n",
        "    results.append(result)\n",
        "\n",
        "  detection = np.sum(np.array(results) > detection_threshold)\n",
        "  verification = detection / len(os.listdir(os.path.join(VALIDATION_PATH)))\n",
        "  verified = verification > verification_threshold\n",
        "\n",
        "  return verified"
      ],
      "metadata": {
        "id": "oDzkqSVHBCjd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "capture = cv2.VideoCapture(3)\n",
        "\n",
        "while capture.isOpened() :\n",
        "  ret, frame = capture.read()\n",
        "  frame = frame[100 : 350, 200 : 450, : ]\n",
        "\n",
        "  if cv2.waitKey(1) & 0XFF == ord(\"i\") :\n",
        "    img_name = os.path.join(INPUT_PATH, \"img.jpg\")\n",
        "    cv2.imwrite(img_name, frame)\n",
        "    verified = verify(model, 0.7, 0.9)\n",
        "    if verified ==  True :\n",
        "      print(\"You are verified\")\n",
        "    else :\n",
        "      print(\"Sorry, couldn't verify you\")\n",
        "\n",
        "  cv2.imshow(\"Input Image\", frame)\n",
        "\n",
        "  if cv2.waitKey(1) & 0XFF == ord(\"q\") :\n",
        "    break\n",
        "\n",
        "capture.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "ZYf0py_UIl6j"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}