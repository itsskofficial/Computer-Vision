{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install kaggle tensorflow nltk"
      ],
      "metadata": {
        "id": "nNhKTvZZDFXc",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir ~/.kaggle"
      ],
      "metadata": {
        "id": "IoBQl-IjERD_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp kaggle.json ~/.kaggle/"
      ],
      "metadata": {
        "id": "qSDYYYesEWoP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "3TflxGAcEbaB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d adityajn105/flickr8k"
      ],
      "metadata": {
        "id": "Ncx7uAgpEqYk",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip flickr8k.zip"
      ],
      "metadata": {
        "id": "Mos-sYmaE0SW",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lQxoWGzYBBg6"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pickle\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from tqdm.notebook import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from nltk.translate.bleu_score import corpus_bleu\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.utils import to_categorical, plot_model\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "from tensorflow.keras.layers import Input, Dense, LSTM, Embedding, Dropout, add"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DATASET_DIR = 'Images'"
      ],
      "metadata": {
        "id": "wcinUpG8Cf6l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = VGG16()\n",
        "model = Model(inputs = model.inputs, outputs = model.layers[-2].output)"
      ],
      "metadata": {
        "id": "uNqBZSXQFDX_",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features = {}\n",
        "for img_name in tqdm(os.listdir(DATASET_DIR)):\n",
        "  img_path = DATASET_DIR + '/' + img_name\n",
        "  img = load_img(img_path, target_size = (224, 224))\n",
        "  img = img_to_array(img)\n",
        "  img = img.reshape((1, img.shape[0], img.shape[1], img.shape[2]))\n",
        "  img = preprocess_input(img)\n",
        "  feature = model.predict(img, verbose = 0)\n",
        "  img_id = img_name.split('.')[0]\n",
        "  features[img_id] = feature"
      ],
      "metadata": {
        "id": "iP-3fSMiF7IV",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pickle.dump(features, open(\"features.pkl\", \"wb\"))"
      ],
      "metadata": {
        "id": "1j5IleHoJQDG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"features.pkl\" ,\"rb\") as f:\n",
        "  features = pickle.load(f)"
      ],
      "metadata": {
        "id": "2zgRL4kjJeJL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"captions.txt\", \"r\") as f:\n",
        "  next(f)\n",
        "  captions = f.read()"
      ],
      "metadata": {
        "id": "i-LnDqqoJvE_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mapping = {}\n",
        "for line in tqdm(captions.split(\"\\n\")):\n",
        "  tokens = line.split(\",\")\n",
        "  if len(line) < 2:\n",
        "    continue\n",
        "  img_id, caption = tokens[0].split(\".\")[0], tokens[1]\n",
        "  if img_id not in mapping:\n",
        "    mapping[img_id] = []\n",
        "  mapping[img_id].append(caption)"
      ],
      "metadata": {
        "id": "_UOI4XeIKEwQ",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(mapping)"
      ],
      "metadata": {
        "id": "ZiImXL-EMHbi",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mapping"
      ],
      "metadata": {
        "id": "JkpwRW2fO4XJ",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean(mapping):\n",
        "  for key, captions in mapping.items():\n",
        "    for i in range(len(captions)):\n",
        "      caption = captions[i]\n",
        "      caption = caption.lower()\n",
        "      caption = caption.replace(\"[^A-Za-z]\", \"\")\n",
        "      caption = caption.replace(\"\\s+\", \" \")\n",
        "      caption = \"start \" + \" \".join([word for word in caption.split(\" \") if len(word) > 1]) + \" end\"\n",
        "      captions[i] = caption"
      ],
      "metadata": {
        "id": "WSSvnQIpMbmF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clean(mapping)"
      ],
      "metadata": {
        "id": "3B9zbf7JOFoD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mapping"
      ],
      "metadata": {
        "id": "KfXImE5IPk28",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "captions = []\n",
        "for key in mapping:\n",
        "  for caption in mapping[key]:\n",
        "    captions.append(caption)"
      ],
      "metadata": {
        "id": "JGdM-_FoOZWl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "captions[:5]"
      ],
      "metadata": {
        "id": "h5lI78-hOtki",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(captions)\n",
        "vocab_size = len(tokenizer.word_index) + 1"
      ],
      "metadata": {
        "id": "GjaeK4CyJX4a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"tokenizer.pkl\", \"wb\") as file:\n",
        "\n",
        "    pickle.dump(tokenizer, file)"
      ],
      "metadata": {
        "id": "vf1aIi8ZUZb3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size"
      ],
      "metadata": {
        "id": "jhzKf195JkWm",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_length = max(len(caption.split()) for caption in captions)"
      ],
      "metadata": {
        "id": "t78z3LFvJm-C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_length"
      ],
      "metadata": {
        "id": "mNiEAQGWJ5yx",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_ids = list(mapping.keys())\n",
        "split = int(len(image_ids) * 0.9)\n",
        "train = image_ids[: split]\n",
        "test = image_ids[split :]\n",
        "len(train), len(test)"
      ],
      "metadata": {
        "id": "Y76ICCY3J6c2",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def data_generator(data_keys, mapping, features, tokenizer, max_length, vocab_size, batch_size) :\n",
        "  X1, X2, y = list(), list(), list()\n",
        "  n = 0\n",
        "\n",
        "  while True :\n",
        "    for key in data_keys :\n",
        "      n += 1\n",
        "      captions = mapping[key]\n",
        "\n",
        "      for caption in captions :\n",
        "        seq = tokenizer.texts_to_sequences([caption])[0]\n",
        "        for i in range(1, len(seq)) :\n",
        "          in_seq, out_seq = seq[: i], seq[i]\n",
        "          in_seq = pad_sequences([in_seq], maxlen = max_length)[0]\n",
        "          out_seq = to_categorical([out_seq], num_classes = vocab_size)[0]\n",
        "          X1.append(features[key][0])\n",
        "          X2.append(in_seq)\n",
        "          y.append(out_seq)\n",
        "\n",
        "      if n ==  batch_size :\n",
        "        X1, X2, y = np.array(X1), np.array(X2), np.array(y)\n",
        "        yield [X1, X2], y\n",
        "\n",
        "        X1, X2, y = list(), list(), list()\n",
        "        n = 0"
      ],
      "metadata": {
        "id": "yi4ywhqkKd8_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_layer_1 = Input(shape = (4096))\n",
        "dropout_layer_1 = Dropout(0.4)(input_layer_1)\n",
        "dense_layer_1 = Dense(256, activation = \"relu\")(dropout_layer_1)\n",
        "\n",
        "input_layer_2 = Input(shape = (max_length))\n",
        "embedding_layer = Embedding(vocab_size, 256, mask_zero = True)(input_layer_2)\n",
        "dropout_layer_2 = Dropout(0.4)(embedding_layer)\n",
        "lstm_layer = LSTM(256)(dropout_layer_2)"
      ],
      "metadata": {
        "id": "2scsmSAxLGsS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decoder_layer_1 = add([dense_layer_1, lstm_layer])\n",
        "decoder_layer_2 = Dense(256, activation = \"relu\")(decoder_layer_1)\n",
        "output_layer = Dense(vocab_size, activation = \"softmax\")(decoder_layer_2)"
      ],
      "metadata": {
        "id": "oLjzwIArQBM5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model(inputs = [input_layer_1, input_layer_2], outputs = output_layer)\n",
        "model.compile(loss = \"categorical_crossentropy\", optimizer = \"adam\")"
      ],
      "metadata": {
        "id": "P_-PyyOZQhCG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_model(model, show_shapes =  True)"
      ],
      "metadata": {
        "id": "nduO1qZ9QySe",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(15) :\n",
        "  generator = data_generator(data_keys = train, mapping = mapping, features = features, tokenizer = tokenizer, max_length = max_length, vocab_size = vocab_size, batch_size = 64)\n",
        "  model.fit(generator, epochs = 1, steps_per_epoch = len(train) // 64, verbose = 1)"
      ],
      "metadata": {
        "id": "1ISZbeXbRhS8",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"model.model\")"
      ],
      "metadata": {
        "id": "GZU4d1ijRNJL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r model.zip \"model.model\""
      ],
      "metadata": {
        "id": "H4D_TcdojB1U",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def index_to_word(y, tokenizer) :\n",
        "  for word, index in tokenizer.word_index.items():\n",
        "    if index == y :\n",
        "      return word\n",
        "  return None"
      ],
      "metadata": {
        "id": "IgvvlEDgVinE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_caption(model, image, tokenizer, max_length) :\n",
        "  in_text = \"start\"\n",
        "  for i in range(max_length) :\n",
        "    sequence = tokenizer.texts_to_sequences([in_text])[0]\n",
        "    sequence = pad_sequences([sequence], max_length)\n",
        "    prediction = model.predict([image, sequence], verbose = 1)\n",
        "    result = np.argmax(prediction)\n",
        "    word = index_to_word(result, tokenizer)\n",
        "\n",
        "    if word is None :\n",
        "      break\n",
        "\n",
        "    in_text += \" \" + word\n",
        "\n",
        "    if word == \"end\" :\n",
        "      break\n",
        "\n",
        "  return in_text"
      ],
      "metadata": {
        "id": "z9qYXK6fWYAG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "actual, predicted = list(), list()\n",
        "\n",
        "for key in tqdm(test) :\n",
        "  captions = mapping[key]\n",
        "  y_pred = predict_caption(model, features[key], tokenizer, max_length)\n",
        "  actual_caption = [caption.split() for caption in captions]\n",
        "  predicted_caption = y_pred.split()\n",
        "  actual.append(actual_caption)\n",
        "  predicted.append(predicted_caption)\n",
        "\n",
        "print(f\"BLEU-1 : {corpus_bleu(actual, predicted, weights = (1, 0, 0, 0, 0))}\")\n",
        "print(f\"BLEU-2 : {corpus_bleu(actual, predicted, weights = (0.5, 0.5, 0, 0, 0))}\")"
      ],
      "metadata": {
        "id": "Z-u5JsvyYdJS",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_model = VGG16()\n",
        "img_model = Model(inputs = img_model.inputs, outputs = img_model.layers[-2].output)"
      ],
      "metadata": {
        "id": "q1vntVBMWsDa",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_caption(img_path, img_model, model, tokenizer, max_length) :\n",
        "  img_path = \"\"\n",
        "  img = load_img(img_path, target_size = (224, 224))\n",
        "  img = img_to_array(img)\n",
        "  img = img.reshape((1, img.shape[0], img.shape[1], img.shape[2]))\n",
        "  img = preprocess_input(img)\n",
        "  feature = img_model.predict(img, verbose = 0)\n",
        "  y_pred = predict_caption(model, feature, tokenizer, max_length)\n",
        "  return y_pred"
      ],
      "metadata": {
        "id": "4aq4A120VXG_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "caption = generate_caption(\"boat.jpg\", img_model, model, tokenizer, max_length)"
      ],
      "metadata": {
        "id": "IYrDC9JmXDDM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img = Image.open(\"boat.jpg\")\n",
        "plt.imshow(img)\n",
        "print(caption)"
      ],
      "metadata": {
        "id": "WwdyqClkYTyf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}